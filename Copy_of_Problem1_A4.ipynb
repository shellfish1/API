{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpWJ+GoFMX1G0MuAoT5tem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shellfish1/API/blob/master/Copy_of_Problem1_A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M64xzsFE4vRD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras import metrics\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(n, x1_low, x1_high, x2_low, x2_high, ulc1, ulc2, ulc3, side, fpp, fnp):\n",
        "    x_min = [x1_low, x2_low]\n",
        "    x_max = [x1_high, x2_high]\n",
        "    labels = np.empty([n, 1])\n",
        "\n",
        "    features = np.random.uniform(low=x_min, high=x_max, size=(n, 2))\n",
        "\n",
        "    for i in range(0, n):\n",
        "      labels[i] = label_point(features[i][0], features[i][1], side, ulc1, ulc2, ulc3, fpp, fnp)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def label_point(x1, x2, side, ulc1, ulc2, ulc3, fpp, fnp):\n",
        "    in1 = lambda x, y: ulc1[0] <= x <= ulc1[0] + side and ulc1[1] - side <= y <= ulc1[1]\n",
        "    in2 = lambda x, y: ulc2[0] <= x <= ulc2[0] + side and ulc2[1] - side <= y <= ulc2[1]\n",
        "    in3 = lambda x, y: ulc3[0] <= x <= ulc3[0] + side and ulc3[1] - side <= y <= ulc3[1]\n",
        "\n",
        "    sign = 1 if in1(x1, x2) or in2(x1, x2) or in3(x1, x2) else 0\n",
        "    # TODO: Introduce noise or asymmetry in data, by flipping the flag for asymmetric noise\n",
        "    if sign == 1:\n",
        "        # Noise is 3% false negatives\n",
        "        sign = 1 if random.randint(0, 100) < fpp else 0\n",
        "    else:\n",
        "        # Noise is 1% false positives,\n",
        "        sign = 0 if random.randint(0, 100) < fnp else 1\n",
        "    return sign\n",
        "\n",
        "\n",
        "def plot_data(features, labels):\n",
        "    # Use this method to plot the input data red(o) for points within squares (+), green(x) for points outside squares (-)\n",
        "    x1_1 = []\n",
        "    x2_1 = []\n",
        "\n",
        "    x1_2 = []\n",
        "    x2_2 = []\n",
        "\n",
        "    for i in range(0, len(features)):\n",
        "        x1 = features[i][0]\n",
        "        x2 = features[i][1]\n",
        "        sign = labels[i]\n",
        "\n",
        "        if sign == 1:\n",
        "            x1_1.append(x1)\n",
        "            x2_1.append(x2)\n",
        "        else:\n",
        "            x1_2.append(x1)\n",
        "            x2_2.append(x2)\n",
        "\n",
        "    plt.plot(x1_1, x2_1, marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"red\", linestyle='')\n",
        "    plt.plot(x1_2, x2_2, marker=\"x\", markersize=5, markeredgecolor=\"green\", markerfacecolor=\"green\", linestyle='')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9dlPZw7q4wlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_threshold_model(model, test_features, test_labels):\n",
        "  best_roc_score = 0\n",
        "  best_threshold = 0\n",
        "  test_roc = []\n",
        "  print(\"ROC Score: \", skl.metrics.roc_auc_score(test_labels, model.predict(test_features)))\n",
        "  for t in [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:\n",
        "    label_predictions =  np.where( model.predict(test_features) > 0.2, 1, 0 )\n",
        "    score = skl.metrics.roc_auc_score(test_labels, label_predictions)\n",
        "    test_roc.append(score)\n",
        "    if score >= best_roc_score:\n",
        "      best_threshold = t\n",
        "      best_roc_score = score\n",
        "  print(\"All ROC scores: \", test_roc)\n",
        "  print(\"Best threshold is: \", best_threshold)\n",
        "  return best_threshold\n",
        "\n",
        "\n",
        "def predict_using_kfold_model(models, test_features, thresholds):\n",
        "  \n",
        "  temp_predictions = np.empty([len(test_features), len(models)])\n",
        "  \n",
        "  for j in range(0, len(models)):\n",
        "    thresholded_prediction = np.where( models[j].predict(test_features) > thresholds[j], 1, 0 )\n",
        "    for i in range(0, len(thresholded_prediction)):\n",
        "      temp_predictions[i][j] = thresholded_prediction[i][0]\n",
        "  \n",
        "  final_predictions = np.empty([len(test_features), 1])\n",
        "  \n",
        "  for i in range(0, len(test_features)):\n",
        "    num_zeroes = 0\n",
        "    num_ones = 0\n",
        "    for j in range(0, len(models)):\n",
        "      if temp_predictions[i][j] == 1:\n",
        "        num_ones += 1\n",
        "      else:\n",
        "        num_zeroes += 1\n",
        "    label = 1 if num_ones > num_zeroes else 0\n",
        "    final_predictions[i][0] = label\n",
        "\n",
        "  return final_predictions\n",
        "\n",
        "def compute_scores(labels_true, labels_pred):\n",
        "  accuracy_score = skl.metrics.accuracy_score(labels_true, labels_pred, normalize=True)\n",
        "  balanced_accuracy_score = skl.metrics.balanced_accuracy_score(labels_true, labels_pred)\n",
        "  roc_auc_score = skl.metrics.roc_auc_score(labels_true, labels_pred)\n",
        "  return [accuracy_score, balanced_accuracy_score, roc_auc_score]\n",
        "\n",
        "\n",
        "def train_model(total_features, total_labels, l1_n, l2_n):\n",
        "    \n",
        "    kf = KFold(n_splits=2)\n",
        "    models = []\n",
        "    thresholds = []\n",
        "    \n",
        "    for train_index, test_index in kf.split(total_features, total_labels):\n",
        "      # K fold cross validation\n",
        "      training_features, test_features = total_features[train_index], total_features[test_index]\n",
        "      training_labels, test_labels = total_labels[train_index], total_labels[test_index]\n",
        "\n",
        "      classifier = Sequential()\n",
        "      if l2_n != 0:\n",
        "          classifier.add(Dense(l1_n, activation='tanh', input_dim=2))\n",
        "          classifier.add(Dense(l2_n, activation='tanh'))\n",
        "          classifier.add(Dense(1, activation='sigmoid'))\n",
        "      else:\n",
        "          classifier.add(Dense(l1_n, activation='tanh', input_dim=2))\n",
        "          classifier.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "      classifier.compile(optimizer='adam', loss='binary_crossentropy', run_eagerly=True, metrics=['accuracy'])\n",
        "      classifier.fit(training_features, training_labels, batch_size=10, epochs=100)\n",
        "      # Need to compute metrics with respect to test_labels and training_labels\n",
        "      models.append(classifier)\n",
        "      thresholds.append(predict_threshold_model(classifier, test_features, test_labels))\n",
        "    \n",
        "    # Computing averaged predictions over k folds\n",
        "    labels_pred = predict_using_kfold_model(models, total_features, thresholds)\n",
        "    labels_true = total_labels  \n",
        "\n",
        "    # Computing metrics over predictions\n",
        "    scores = compute_scores(labels_true, labels_pred)\n",
        "\n",
        "    return models, scores\n"
      ],
      "metadata": {
        "id": "GF7zF64u50d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yLSylf3L6x31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    total_features, total_labels = generate_data(1500, -6, 6, -4, 4, [-4, 3], [-2, -1], [2, 1], 3, 96, 98) \n",
        "    validation_features, validation_labels = generate_data(100000, -6, 6, -4, 4, [-4, 3], [-2, -1], [2, 1], 3, 100, 100)\n",
        "    # #     h1 ∈ {1, 4, 12} and h2 ∈ {0, 3},\n",
        "    h1 = [1, 4, 12]\n",
        "    h2 = [0, 3]\n",
        "\n",
        "    model, scores = train_model(total_features, total_labels, 1, 0)\n",
        "    print(scores)\n",
        "\n",
        "    # results = []\n",
        "    # # h1 | h2 | D | FIG | TEST ROC | TEST ACC | TEST BAL ACC | VAL ROC | VAL ACC | VAL BAL ACC # \n",
        "    # for l1_n in h1:\n",
        "    #     for l2_n in h2:\n",
        "    #       for n in [250, 1000, 10000]:\n",
        "    #         for i in [1,2]:\n",
        "\n",
        "    #           row = np.empty(10)\n",
        "    #           row[0] = l1_n\n",
        "    #           row[1] = l2_n\n",
        "    #           row[2] = n\n",
        "    #           row[3] = i\n",
        "\n",
        "    #           if i == 1:\n",
        "    #             ## FOR FIG1\n",
        "    #             total_features1, total_labels1 = generate_data(n, -6, 6, -4, 4, [-4, 3], [-2, -1], [2, 1], 3, 96, 98) \n",
        "    #             validation_features1, validation_labels1 = generate_data(100000, -6, 6, -4, 4, [-4, 3], [-2, -1], [2, 1], 3, 100, 100)\n",
        "    #             model1, scores1 = train_model(total_features1, total_labels1, l1_n, l2_n)\n",
        "\n",
        "    #             row[4] = scores1[0]\n",
        "    #             row[5] = scores1[1]\n",
        "    #             row[6] = scores1[2]\n",
        "\n",
        "    #             validation_labels_pred = predict_using_kfold_model(model1, validation_features1)\n",
        "    #             validation_scores = compute_scores(validation_labels1, validation_labels_pred)\n",
        "\n",
        "    #             row[7] = validation_scores[0]\n",
        "    #             row[8] = validation_scores[1]\n",
        "    #             row[9] = validation_scores[2]\n",
        "    #           else:\n",
        "    #             ## FOR FIG2\n",
        "    #             total_features2, total_labels2 = generate_data(n, -6, 6, -4, 4, [-4, 3], [-1, -2], [2, 0], 1, 96, 98) \n",
        "    #             validation_features2, validation_labels2 = generate_data(100000, -6, 6, -4, 4, [-4, 3], [-1, -2], [2, 0], 1, 100, 100)\n",
        "    #             model2, scores2 = train_model(total_features1, total_labels1, l1_n, l2_n)\n",
        "\n",
        "    #             row[4] = scores2[0]\n",
        "    #             row[5] = scores2[1]\n",
        "    #             row[6] = scores2[2]\n",
        "\n",
        "    #             validation_labels_pred = predict_using_kfold_model(model2, validation_features2)\n",
        "    #             validation_scores = compute_scores(validation_labels2, validation_labels_pred)\n",
        "\n",
        "    #             row[7] = validation_scores[0]\n",
        "    #             row[8] = validation_scores[1]\n",
        "    #             row[9] = validation_scores[2]\n",
        "              \n",
        "    #           results.append(row)\n",
        "\n",
        "    # print(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "SB8R25-T53hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E6zyWVaG6KxV"
      }
    }
  ]
}